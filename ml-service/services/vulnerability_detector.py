# services/vulnerability_detector.py
import ast
from typing import List
from models.schemas import SecurityIssue

class VulnerabilityDetector:
    def __init__(self):
        self.language_analyzers = {
            "python": self._analyze_python,
            "javascript": self._analyze_javascript,
            "go": self._analyze_go
        }
        
        self.common_patterns = {
            "sql_injection": {
                "patterns": [
                    r".*execute\(.*\+.*\)",
                    r".*query\(.*\+.*\)",
                ],
                "severity": "high",
                "message": "Potential SQL injection vulnerability"
            },
            "command_injection": {
                "patterns": [
                    r"os\.system\(",
                    r"subprocess\.call\(",
                    r"exec\(",
                    r"eval\("
                ],
                "severity": "high",
                "message": "Potential command injection vulnerability"
            },
            "weak_crypto": {
                "patterns": [
                    r"md5\(",
                    r"sha1\("
                ],
                "severity": "medium",
                "message": "Weak cryptographic algorithm detected"
            }
        }

    def detect(self, code: str, language: str) -> List[SecurityIssue]:
        language = language.lower()
        analyzer = self.language_analyzers.get(language, self._analyze_generic)
        return analyzer(code)
    
    def _analyze_python(self, code: str) -> List[SecurityIssue]:
        issues = []
        try:
            tree = ast.parse(code)
            for node in ast.walk(tree):
                # Check for dangerous function calls
                if isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Name):
                        if node.func.id in ['eval', 'exec']:
                            issues.append(SecurityIssue(
                                severity="high",
                                description=f"Dangerous {node.func.id}() function used",
                                line_number=node.lineno,
                                recommendation=f"Avoid using {node.func.id}(). Consider safer alternatives."
                            ))
                
                # Check for hardcoded secrets
                if isinstance(node, ast.Assign):
                    for target in node.targets:
                        if isinstance(target, ast.Name):
                            if any(secret in target.id.lower() for secret in ['password', 'secret', 'key']):
                                issues.append(SecurityIssue(
                                    severity="medium",
                                    description="Potential hardcoded secret detected",
                                    line_number=node.lineno,
                                    recommendation="Use environment variables or secure secret management."
                                ))
        except SyntaxError:
            issues.append(SecurityIssue(
                severity="low",
                description="Could not parse Python code for security analysis",
                line_number=1,
                recommendation="Ensure code is syntactically correct."
            ))
        
        return issues
    
    def _analyze_javascript(self, code: str) -> List[SecurityIssue]:
        issues = []
        dangerous_patterns = [
            (r"eval\(", "high", "Dangerous eval() usage"),
            (r"innerHTML\s*=", "medium", "Potential XSS vulnerability"),
            (r"document\.write\(", "medium", "Potential XSS vulnerability"),
            (r"localStorage\.", "low", "Sensitive data in localStorage")
        ]
        
        for line_num, line in enumerate(code.split('\n'), 1):
            for pattern, severity, message in dangerous_patterns:
                if pattern in line:
                    issues.append(SecurityIssue(
                        severity=severity,
                        description=message,
                        line_number=line_num,
                        recommendation="Consider using safer alternatives."
                    ))
        
        return issues
    
    def _analyze_go(self, code: str) -> List[SecurityIssue]:
        issues = []
        dangerous_patterns = [
            (r"sql\.Open\(", "medium", "SQL connection without context"),
            (r"exec\.Command\(", "high", "Potential command injection"),
            (r"json\.Unmarshal\(", "low", "Potential JSON unmarshal vulnerability")
        ]
        
        for line_num, line in enumerate(code.split('\n'), 1):
            for pattern, severity, message in dangerous_patterns:
                if pattern in line:
                    issues.append(SecurityIssue(
                        severity=severity,
                        description=message,
                        line_number=line_num,
                        recommendation="Use context and proper input validation."
                    ))
        
        return issues
    
    def _analyze_generic(self, code: str) -> List[SecurityIssue]:
        issues = []
        for line_num, line in enumerate(code.split('\n'), 1):
            for vuln_type, config in self.common_patterns.items():
                for pattern in config["patterns"]:
                    if pattern in line:
                        issues.append(SecurityIssue(
                            severity=config["severity"],
                            description=config["message"],
                            line_number=line_num,
                            recommendation="Review and implement secure coding practices."
                        ))
        return issues